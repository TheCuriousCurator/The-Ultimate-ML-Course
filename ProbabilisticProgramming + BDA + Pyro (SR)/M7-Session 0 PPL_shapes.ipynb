{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pyro\n",
    "from pyro.distributions import Bernoulli, Categorical, MultivariateNormal, Normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Mon Jun 24 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.19\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "pyro : 1.9.1\n",
      "torch: 2.3.0\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "d = Bernoulli(0.5)\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == ()\n",
    "assert d.log_prob(x).shape == ()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 1., 0.],\n",
      "        [1., 0., 0., 0.],\n",
      "        [0., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# Distributions can be batched by passing in batched parameters.\n",
    "d = Bernoulli(0.5 * torch.ones(3,4))\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.1000, 0.2000, 0.3000, 0.4000])\n",
      "tensor([[0.1000, 0.2019, 0.2998, 0.3999],\n",
      "        [0.1004, 0.2008, 0.3002, 0.3992],\n",
      "        [0.1000, 0.2002, 0.2999, 0.3993]])\n"
     ]
    }
   ],
   "source": [
    "# Another way to batch distributions is via the .expand() method. \n",
    "# This only works if parameters are identical along the leftmost dimensions.\n",
    "batch = torch.tensor([0.1, 0.2, 0.3, 0.4])\n",
    "print(batch)\n",
    "d = Bernoulli(batch).expand([3, 4])\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)\n",
    "\n",
    "n = 100000\n",
    "for i in range(n):\n",
    "    x = x + d.sample()\n",
    "print(x/(n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.1000],\n",
      "        [0.2000],\n",
      "        [0.3000]])\n",
      "tensor([[0.1005, 0.1000, 0.0988, 0.0991],\n",
      "        [0.2007, 0.1982, 0.2000, 0.2005],\n",
      "        [0.3004, 0.3008, 0.3001, 0.2987]])\n"
     ]
    }
   ],
   "source": [
    "# Another way to batch distributions is via the .expand() method. \n",
    "# This only works if parameters are identical along the leftmost dimensions.\n",
    "batch = torch.tensor([[0.1], [0.2], [0.3]])\n",
    "print(batch)\n",
    "d = Bernoulli(batch).expand([3, 4])\n",
    "assert d.batch_shape == (3, 4)\n",
    "assert d.event_shape == ()\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3, 4)\n",
    "\n",
    "n = 100000\n",
    "for i in range(n):\n",
    "    x = x + d.sample()\n",
    "print(x/(n+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-3.1385)\n"
     ]
    }
   ],
   "source": [
    "d = MultivariateNormal(torch.zeros(3), torch.eye(3, 3))\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == (3,)\n",
    "x = d.sample()\n",
    "assert x.shape == (3,)            # == batch_shape + event_shape\n",
    "assert d.log_prob(x).shape == ()  # == batch_shape\n",
    "print(d.log_prob(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reshaping Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Pyro you can treat a univariate distribution as multivariate by calling the .to_event(n) property \n",
    "# where n is the number of batch dimensions (from the right) to declare as dependent.\n",
    "\n",
    "d = Bernoulli(0.5 * torch.ones(3,4))\n",
    "assert d.batch_shape == (3,4)\n",
    "assert d.event_shape == ()\n",
    "\n",
    "d = d.to_event(1)\n",
    "assert d.batch_shape == (3,)\n",
    "assert d.event_shape == (4,)\n",
    "\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == (3,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Pyro you can treat a univariate distribution as multivariate by calling the .to_event(n) property \n",
    "# where n is the number of batch dimensions (from the right) to declare as dependent.\n",
    "\n",
    "# we need to ensure that batch_shape is carefully controlled by either trimming it down using .to_event(n)\n",
    "# or by declaring dimensions as independent by using pyro.plate \n",
    "d = Bernoulli(0.5 * torch.ones(3,4))\n",
    "assert d.batch_shape == (3,4)\n",
    "assert d.event_shape == ()\n",
    "\n",
    "d = d.to_event(2)\n",
    "assert d.batch_shape == ()\n",
    "assert d.event_shape == (3, 4)\n",
    "\n",
    "x = d.sample()\n",
    "assert x.shape == (3, 4)\n",
    "assert d.log_prob(x).shape == ()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\# log prob size = batch_shape\n",
    "\n",
    "\\# samples have shape = batch_shape + event_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Safe to assume dependence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([])\n",
      "torch.Size([10]) torch.Size([])\n",
      "torch.Size([]) torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "d = Normal(0, 1)\n",
    "print(d.batch_shape, d.event_shape)\n",
    "d = d.expand([10])\n",
    "print(d.batch_shape, d.event_shape)\n",
    "d = d.to_event(1)\n",
    "print(d.batch_shape, d.event_shape)\n",
    "x = pyro.sample(\"x\", d)\n",
    "assert x.shape == (10,)\n",
    "\n",
    "# assumes conditional independence\n",
    "# plate informs Pyro that it can make use of conditional independence information when estimating gradients, \n",
    "# whereas in the first version Pyro must assume they are dependent (even though the normals are in fact conditionally independent). \n",
    "with pyro.plate(\"x_plate\", 10):\n",
    "    x = pyro.sample(\"x\", Normal(0, 1))  # .expand([10]) is automatic\n",
    "assert x.shape == (10,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([]) torch.Size([])\n",
      "torch.Size([10, 3]) torch.Size([])\n",
      "torch.Size([10]) torch.Size([3])\n",
      "tensor([-4.5822, -2.9822, -3.9823, -3.1746, -2.8273, -8.0561, -7.0914, -2.9798,\n",
      "        -2.8291, -3.3716])\n"
     ]
    }
   ],
   "source": [
    "d = Normal(0, 1)\n",
    "print(d.batch_shape, d.event_shape)\n",
    "d = d.expand([10, 3])\n",
    "print(d.batch_shape, d.event_shape)\n",
    "d = d.to_event(1)\n",
    "print(d.batch_shape, d.event_shape)\n",
    "x = pyro.sample(\"x\", d)\n",
    "assert x.shape == (10,3)\n",
    "assert d.log_prob(x).shape == (10,)\n",
    "print(d.log_prob(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
