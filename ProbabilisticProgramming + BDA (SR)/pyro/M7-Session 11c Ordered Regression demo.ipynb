{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now going to learn about mixture models; models that combine pieces of several different distributions in intereting ways. These types of models can help with over-dispersion, zero-inflation, and ordered categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, re, warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "from scipy.special import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "tt =  torch.tensor\n",
    "from torch.distributions import TransformedDistribution\n",
    "import pyro\n",
    "from pyro.distributions import (\n",
    "    BetaBinomial,\n",
    "    Binomial,\n",
    "    Categorical,\n",
    "    Delta,\n",
    "    Dirichlet,\n",
    "    Exponential,\n",
    "    Gamma,\n",
    "    GammaPoisson,\n",
    "    Normal,\n",
    "    Poisson,\n",
    "    TorchDistribution,\n",
    "    TransformedDistribution,\n",
    "    ZeroInflatedPoisson,\n",
    "    OrderedLogistic\n",
    ")\n",
    "from torch.distributions import Distribution\n",
    "Distribution.set_default_validate_args(False)\n",
    "\n",
    "from pyro.distributions.transforms import Transform\n",
    "from pyro.ops.stats import hpdi, waic, resample\n",
    "from pyro.infer import Predictive\n",
    "from pyro.distributions import constraints\n",
    "import arviz as az \n",
    "from utils import train_nuts, unnest_samples, traceplot, precis, plot_intervals\n",
    "\n",
    "torch.multiprocessing.set_sharing_strategy(\"file_system\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Sun Sep 15 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.9.19\n",
      "IPython version      : 8.18.1\n",
      "\n",
      "torch     : 2.3.0\n",
      "arviz     : 0.17.1\n",
      "sys       : 3.9.19 (main, May  6 2024, 19:43:03) \n",
      "[GCC 11.2.0]\n",
      "scipy     : 1.12.0\n",
      "pyro      : 1.9.1\n",
      "re        : 2.2.1\n",
      "matplotlib: 3.9.0\n",
      "numpy     : 1.26.4\n",
      "pandas    : 2.2.2\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext watermark\n",
    "%watermark -n -u -v -iv -w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code 12.12 - 12.29\n",
    "Now we will discuss ordered categorical models. This type of model arises whenever we have a categorical variable that doesn't have a direct numerical interpretation, but nevertheless does have some sort of order (e.g. \"worst\" < \"bad\" < \"good\" < \"better\" < \"best\"). We will analyze this in the context of \"trolley problems\", where someone is placed in a hypothetical situation involving a runaway trolley which will end up killing various people depending on the choices made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9930 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>story</th>\n",
       "      <th>age</th>\n",
       "      <th>male</th>\n",
       "      <th>edu</th>\n",
       "      <th>action</th>\n",
       "      <th>intention</th>\n",
       "      <th>contact</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4146</th>\n",
       "      <td>aqu</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5454</th>\n",
       "      <td>che</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>Some College</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3892</th>\n",
       "      <td>spe</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>Some College</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7993</th>\n",
       "      <td>boa</td>\n",
       "      <td>57</td>\n",
       "      <td>1</td>\n",
       "      <td>Graduate Degree</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8828</th>\n",
       "      <td>box</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>Some College</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6108</th>\n",
       "      <td>box</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Some College</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     story  age  male              edu  action  intention  contact  response\n",
       "4146   aqu   43     0  Graduate Degree       1          0        0         4\n",
       "5454   che   38     1     Some College       0          1        0         7\n",
       "3892   spe   37     0     Some College       1          1        0         1\n",
       "7993   boa   57     1  Graduate Degree       0          0        0         3\n",
       "8828   box   21     1     Some College       1          0        0         3\n",
       "6108   box   28     0     Some College       1          1        0         4"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trolley_df = pd.read_csv(\"data/Trolley.csv\", sep=\";\")\n",
    "print(len(trolley_df), \"rows\")\n",
    "trolley_df[[\"story\", \"age\", \"male\", \"edu\", \"action\", \"intention\", \"contact\", \"response\"]].sample(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to enforce the ordering of the response variables (so that increasing one of the associated predictor variables increases the response), we will use a cumulative link function. Basically, each outcome level gets its own \"intercept\" $\\alpha_k$ that is related to the cumulative probability via\n",
    "$$\n",
    "\\log\\left(\\frac{Pr(y_i \\le k)}{1 - Pr(y_i \\le k)}\\right) = \\alpha_k\n",
    "$$\n",
    "You will notice that this is the logit function, so its inverse is the sigmoid $Pr(y_i \\le k) = \\sigma(\\alpha_k) = e^{\\alpha_k}/(1+e^{\\alpha_k})$. The idea is that as we introduce predictor variables, we add them onto $\\alpha_k$ as a linear model, then do the sigmoid thing to convert them into cumulative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14226/752784804.py:6: RuntimeWarning: divide by zero encountered in divide\n",
      "  x = np.log(y/(1-y))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0ee65a9cb94715bfac11704f6b6e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=-1.0, description='φ', max=2.0, min=-2.0), Output()), _dom_classes=('w…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_cumulative_logit(φ)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from ipywidgets import *\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "x, y = np.unique(trolley_df[\"response\"], return_counts=True)\n",
    "y = np.cumsum(y)/y.sum()\n",
    "x = np.log(y/(1-y))\n",
    "title = r\"$ \\log \\frac{P(y_i \\leq k)}{1 - P(y_i \\leq k)} = \\alpha_k + \\phi_i$\"\n",
    "font = {'family': 'serif',\n",
    "        'color':  'dodgerblue',\n",
    "        'weight': 'normal',\n",
    "        'size': 12,\n",
    "        }\n",
    "plt.ion()\n",
    "\n",
    "def plot_cumulative_logit(ϕ):\n",
    "    global x\n",
    "    clear_output(wait=True)\n",
    "    fig, axes = plt.subplots(ncols=2, figsize=(10, 5))\n",
    "    x_minus_phi = x + ϕ\n",
    "    y = torch.sigmoid(tt(x_minus_phi))\n",
    "    # [0.0514, 0.0939, 0.1520, 0.3203, 0.4725, 0.6834, 1.0000]\n",
    "    plt.sca(axes[0])\n",
    "    plt.stem(x_minus_phi, y, linefmt='--')\n",
    "    plt.ylabel(\"cumulative proportion\")\n",
    "    plt.xlabel(\"log-cumulative odds\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.vlines(ϕ, 0, 1.1, ls=\"-\", color=\"k\")\n",
    "    for idx in range(len(x_minus_phi)-1):\n",
    "        plt.hlines(y[idx], -6, x_minus_phi[idx],  ls=\"--\")\n",
    "        plt.title(title)\n",
    "    for idx in range(len(x_minus_phi[:-1])):\n",
    "        plt.text(x_minus_phi[idx], -0.05, rf\"$\\alpha_{idx+1}$\", fontdict=font)\n",
    "    plt.sca(axes[1])\n",
    "    pk = []\n",
    "    for idx in range(len(x_minus_phi)-1):\n",
    "        idxx = len(x_minus_phi) - 1 - idx\n",
    "        val = y[idxx].item() - y[idxx-1].item()\n",
    "        pk.append(val)\n",
    "    pk.append(y[0].item())\n",
    "    pk = pk[::-1]\n",
    "    pk = np.array(pk)\n",
    "    xx = [x+1 for x in range(len(pk))]\n",
    "    plt.bar(xx, pk)\n",
    "    plt.ylabel(\"probability\")\n",
    "    plt.xlabel(\"Observed Values\")\n",
    "    plt.ylim(0, 0.7)\n",
    "    #plt.show()\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)\n",
    "    plt.clf()\n",
    "    #fig.canvas.draw()\n",
    "    #fig.canvas.flush_events()\n",
    "    display(fig)\n",
    "    plt.close()\n",
    "    \n",
    "\n",
    "interact(plot_cumulative_logit, ϕ=widgets.FloatSlider(value=-1, min=-2, max=2, step=0.1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom ipywidgets import *\\n\\nx, y = np.unique(trolley_df[\"response\"], return_counts=True)\\ny = np.cumsum(y)/y.sum()\\nx = np.log(y/(1-y))\\n\\ndef plot_cumulative_logit(i):\\n    global x\\n    x_minus_phi = x - i\\n    y = torch.sigmoid(tt(x_minus_phi))\\n    plt.stem(x_minus_phi + i, y, linefmt=\\'--\\')\\n    plt.ylabel(\"cumulative proportion\")\\n    plt.xlabel(\"log-cumulative odds\")\\n    plt.xlim(-6, 6)\\n    plt.vlines(i, 0, 1.1, ls=\"-\", color=\"k\")\\n    for idx in range(len(x_minus_phi)-1):\\n        plt.hlines(y[idx], -6, x_minus_phi[idx] + i,  ls=\"--\")\\n    plt.show()\\n\\ninteract(plot_cumulative_logit, i= widgets.FloatSlider(value=0, min=-2, max=2, step=0.2))\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from ipywidgets import *\n",
    "\n",
    "x, y = np.unique(trolley_df[\"response\"], return_counts=True)\n",
    "y = np.cumsum(y)/y.sum()\n",
    "x = np.log(y/(1-y))\n",
    "\n",
    "def plot_cumulative_logit(i):\n",
    "    global x\n",
    "    x_minus_phi = x - i\n",
    "    y = torch.sigmoid(tt(x_minus_phi))\n",
    "    plt.stem(x_minus_phi + i, y, linefmt='--')\n",
    "    plt.ylabel(\"cumulative proportion\")\n",
    "    plt.xlabel(\"log-cumulative odds\")\n",
    "    plt.xlim(-6, 6)\n",
    "    plt.vlines(i, 0, 1.1, ls=\"-\", color=\"k\")\n",
    "    for idx in range(len(x_minus_phi)-1):\n",
    "        plt.hlines(y[idx], -6, x_minus_phi[idx] + i,  ls=\"--\")\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_cumulative_logit, i= widgets.FloatSlider(value=0, min=-2, max=2, step=0.2))\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
