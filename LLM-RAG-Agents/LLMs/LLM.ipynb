{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell and paste the API key in the prompt\n",
    "import os\n",
    "import configparser\n",
    "# Create a ConfigParser object\n",
    "config = configparser.ConfigParser()\n",
    "\n",
    "# Read the configuration file\n",
    "config.read('.config.ini')\n",
    "os.environ['GOOGLE_API_KEY'] = config.get('GoogleGeminiAPI', 'Google_Gemini_API_KEY')\n",
    "\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = config.get('LangChain', 'LANGCHAIN_TRACING_V2')\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = config.get('LangChain', 'LANGCHAIN_ENDPOINT')\n",
    "os.environ['LANGCHAIN_API_KEY'] = config.get('LangChain', 'LANGCHAIN_API_KEY')\n",
    "os.environ['USER_AGENT'] = config.get('LangChain', 'USER_AGENT')\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = config.get('OpenAI', 'OPENAI_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sundar Pichai, an Indian-American business executive, has been serving as the Chief Executive Officer (CEO) of Alphabet Inc., the parent company of Google, since December 2019. He was appointed CEO after Larry Page stepped down from the role.\\n\\nBefore becoming the CEO of Google, Sundar worked at Google for over a decade and held various leadership positions within the company. In 2004, he joined Google as an engineer in their New York office. Over time, he rose through the ranks to become Vice President of Android Development (2013-2015), then Senior Vice President of Chrome Operating System and Android (2015-2018). He was also responsible for overseeing Google's product portfolio.\\n\\nSundar became CEO after Larry Page stepped down from the role in December 2019. Prior to that, he had been serving as the CEO of Google Cloud since March 2018. As CEO, Sundar has focused on driving innovation and growth within Alphabet Inc., while also prioritizing diversity, equity, and inclusion initiatives.\\n\\nSo, the answer is: Sundar Pichai became the CEO of Google because he was appointed by Larry Page to take over as CEO after stepping down from the role in December 2019. He had previously held\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# create a prompt template where it contains some initial instructions\n",
    "# here we say our LLM to think step by step and give the answer\n",
    "\n",
    "template = \"\"\"\n",
    "Let's think step by step of the question: {question}\n",
    "Based on all the thought the final answer becomes:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# paste the path where your model's weight are located (.bin file)\n",
    "# you can download the models by going to gpt4all's website.\n",
    "# scripts for downloading is also available in the later \n",
    "# sections of this tutorial\n",
    "\n",
    "\n",
    "#local_path = (\"/home/mb600l/conda_env/models/Llama-3.2-1B-Instruct.Q8_0.gguf\")\n",
    "\n",
    "local_path = (\"/home/mb600l/conda_env/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "llm = GPT4All(model=local_path, device='gpu') \n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# initialize the LLM and make chain it with the prompts\n",
    "#llm  = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\", device='gpu') # downloads / loads a 4.66GB LLM\n",
    "#llm  = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\") # downloads / loads a 4.66GB LLM\n",
    "llm = GPT4All(model=local_path, device='gpu') # device='amd', device='intel'\n",
    "#llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# run the chain with your query (question)\n",
    "\n",
    "#llm_chain('Who is the CEO of Google and why he became the ceo of Google?')\n",
    "\n",
    "llm_chain.invoke({\"question\": 'Who is the CEO of Google and why he became the ceo of Google?'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Sundar Pichai, an Indian-American business executive, has been serving as the Chief Executive Officer (CEO) of Alphabet Inc., the parent company of Google, since December 2019. He was appointed CEO after Larry Page stepped down from the role.\\n\\nBefore becoming the CEO of Google, Sundar worked at Google for over a decade and held various leadership positions within the company. In 2004, he joined Google as an engineer in their New York office. Over time, he rose through the ranks to become Vice President of Android Development (2013-2015), then Senior Vice President of Chrome Operating System and Android (2015-2018). He was also responsible for overseeing Google's product portfolio.\\n\\nSundar became CEO after Larry Page stepped down from the role in December 2019. Prior to that, he had been serving as the CEO of Google Cloud since March 2018. As CEO, Sundar has focused on driving innovation and growth within Alphabet Inc., while also prioritizing diversity, equity, and inclusion initiatives.\\n\\nSo, the answer is: Sundar Pichai became the CEO of Google because he was appointed by Larry Page to take over as CEO after stepping down from the role in December 2019. He had previously held\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Larry Page\\n\\nExplanation:\\n\\nThe best answer is Larry Page.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.llms import GPT4All\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "# create a prompt template where it contains some initial instructions\n",
    "# here we say our LLM to think step by step and give the answer\n",
    "\n",
    "template = \"\"\"\n",
    "Let's think step by step of the question: {question}\n",
    "Based on all the thought the final answer becomes:\n",
    "\"\"\"\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "# paste the path where your model's weight are located (.bin file)\n",
    "# you can download the models by going to gpt4all's website.\n",
    "# scripts for downloading is also available in the later \n",
    "# sections of this tutorial\n",
    "\n",
    "\n",
    "local_path = (\"/home/mb600l/conda_env/models/llama-3.2-1b-instruct-q8_0.gguf\")\n",
    "\n",
    "# local_path = (\"/home/mb600l/conda_env/models/Meta-Llama-3-8B-Instruct.Q4_0.gguf\")\n",
    "\n",
    "# initialize the LLM and make chain it with the prompts\n",
    "#llm  = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\", device='gpu') # downloads / loads a 4.66GB LLM\n",
    "#llm  = GPT4All(\"Meta-Llama-3-8B-Instruct.Q4_0.gguf\") # downloads / loads a 4.66GB LLM\n",
    "llm = GPT4All(model=local_path, device='gpu') # device='amd', device='intel'\n",
    "#llm_chain = LLMChain(prompt=prompt, llm=llm, verbose=True)\n",
    "llm_chain = prompt | llm\n",
    "\n",
    "# run the chain with your query (question)\n",
    "\n",
    "#llm_chain('Who is the CEO of Google and why he became the ceo of Google?')\n",
    "llm_chain.invoke({\"question\": 'Who is the CEO of Google and why he became the ceo of Google?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sun, a painter, bold and bright,\n",
      "Across the canvas, paints the light.\n",
      "A golden brush, with strokes so free,\n",
      "Across the hills, the land, the sea.\n",
      "\n",
      "Each dewdrop gleams, a tiny lens,\n",
      "Reflecting rays, in brilliance dense.\n",
      "The flowers wake, their colors bloom,\n",
      "Dispelling shadows, chasing gloom.\n",
      "\n",
      "A warmth that kisses, soft and deep,\n",
      "Where sleepy earth begins to creep\n",
      "From slumber's hold, to greet the day,\n",
      "And chase the lingering night away.\n",
      "\n",
      "The air is sweet, a gentle breeze,\n",
      "Rustles the leaves amongst the trees.\n",
      "A vibrant dance, a joyful sound,\n",
      "As sunshine spills all over ground.\n",
      "\n",
      "So let us bask, in golden grace,\n",
      "And feel the warmth upon our face.\n",
      "For in this light, so pure and true,\n",
      "A perfect day begins anew.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=config.get('GoogleGeminiAPI', 'Google_Gemini_API_KEY'))\n",
    "model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "response = model.generate_content(\"Write a potry for beautiful sunshine\")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
